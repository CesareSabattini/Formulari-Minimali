\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}

\title{Fisica della Materia}
\author{Sabattini Manginella Cesare}
\date{Winter 2024}

\begin{document}

\maketitle

\tableofcontents

\section{Introduzione}
ATTENZIONE: formulario ancora in fase di sviluppo. Alcune informazioni potrebbero essere incomplete o errate.
E' inoltre in corso la riscrittura in inglese.

\section{Microstati e Macrostati}
Considero uno spazio delle configurazioni equiprobabili in un processo di N casistiche binarie, con probabilità:

\begin{equation}
    P(\alpha) = \frac{1}{2^N}
\end{equation}

Ognuna di tali configurazioni è detta "microstato".

Per arrivare al "macrostato" è necessario considerare una proprietà emergente.
Differenti microstati possono definire lo stesso macrostato (ad esempio l'insieme dei microstati aventi la medesima differenza tra i campioni in configurazioni binarie).
Un macrostato è una caratterizzazione dei microstati.
La probabilità di un macrostato è dato dalla somma delle probabilità dei microstati che lo definiscono, normalizzata.
Dunque, ovviamente, microstati con egual probabilità non determinano egual probabilità dei macrostati.

Considerando lo spazio delle fasi delle particelle di gas, di 6N dimensionale, ogni suo punto rappresenta un microstato, mentre un macrostato è definito da un insieme di microstati con le stesse proprietà macroscopiche.


\subsection{Entropia}
Statisticamente, l'entropia misura il grado di "ignoranza" sullo stato microscopico di un sistema termodinamico.
E' possibile definire l'entropia di Boltzmann per un insieme di configurazioni equiprobabili, a partire dalla funzione di partizione:

\begin{equation}
    S = k \log \Omega
\end{equation}

\section{Insieme Microcanonico}
Un insieme di sistemi termodinamicamente isolato si definisce microcanonico.

Il concetto termodinamico di equlibrio termico si traspone in meccanica statistica in quello di massimizzazione del numero di microstati, e dunque dell'entropia.

Considero due sistemi a contatto, che complessivamente definiscono un insieme microcanonico, tali che:

\begin{equation}
    \left\{
    \begin{aligned}
         & U=U_1+U_2                                               \\
         & N=N_1+N_2                                               \\
         & \Omega(N,U_1,U_2) = \Omega_1(N_1,U_1) \Omega_2(N_2,U_2)
    \end{aligned}
    \right.
\end{equation}

Per $N_1, N_2 \rightarrow \infty$, applicando il teorema del limite centrale, si riscontra che le fluttuazioni dai valori di energia che
massimizzano la funzione di molteplicita, essendo proporzionali all'inverso della radice del numero di particelle, sono trascurabili.

Dunque lo stato più probabile in un sistema microcanonico lo è assolutamente.

\subsection{Temperatura}
Si procede di seguito nella ricavazione della temperatura.

Detta $\hat{U}$ l'energia più probabile, si ha:

\begin{equation}
    \begin{aligned}
         & \frac{\partial}{\partial U_1}\Omega(N,U,U_1)|_{U=\hat{U}} = 0 = \\
         & \frac{\partial}{\partial U_1}S(N,U,U_1)|_{U=\hat{U}} = 0
    \end{aligned}
\end{equation}

Come ci si aspettava, per via della monotonia dell'entropia in funzione della molteplicità, essa si massimizza con essa, in funzione dell'energia.

Essendo data la molteplicità dell'insieme microcanonico dalla produttoria delle molteplicità dei sistemi singoli, si ha:
\begin{equation}
    \begin{aligned}
         & \frac{\partial}{\partial U_1}[\Omega(N, U)]_{U=\hat{U}} = \frac{\partial}{\partial U}[\Omega_1(N_1, U_1)\Omega_2(N_2, U_2)]_{U=\hat{U}} =                                     \\
         & \frac{\partial}{\partial U_1}\Omega_1|_{U_1=\hat{U_1}}\Omega_2|_{U_2=\hat{U_2}} + \Omega_1|_{U_1=\hat{U_1}}\frac{\partial}{\partial U_2}\Omega_2|_{U_2=\hat{U_2}} \rightarrow \\
         & \frac{\partial}{\partial U_1}\ln{\Omega_1}|_{U_1=\hat{U_1}}=\frac{\partial}{\partial U_2}\ln{\Omega_2}|_{U_2=\hat{U_2}}
    \end{aligned}
\end{equation}

A partire dalla condizione di massimizzazione del numero dei microstati per la configurazione più probabile, ossia di equilibrio termico,
si definisce la temperatura T attraverso una funzione $\beta$:

\begin{equation}
    \begin{aligned}
         & \beta=\frac{\partial}{\partial U}\Omega(N,U)|_{U=\hat{U}} = \frac{1}{k_BT} \\
    \end{aligned}
\end{equation}

\subsection{Entropia di Gibbs}
L'Entropia di Gibbs generalizza l'entropia di Boltzmann ad insiemi di microstati non equiprobabili:

\begin{equation}
    S_G=-k_B\sum_{i}p_i\ln{p_i}
\end{equation}


\section{Insieme canonico}
Si definisce canonico un insieme di sistemi chiusi, immersi in un bagno termico.

La condizione di massimizzazione dell'entropia di Gibbs a sistema con il fatto che l'energia media deve essere pari a quella del bagno, si traduce nell'aggiunta di un nuovo moltiplicatore di Lagrange:
\begin{equation}
    \begin{aligned}
         & S=-\sum_{j}p_jln{p_j}-\lambda\left(\sum_{j}p_j-1\right)-\beta\left(\sum_{j}\epsilon_jp_j-U\right)                                \\
         & \frac{d}{dp_j}S =0 \rightarrow p_j=e^{-\beta\epsilon_j-\lambda-1} \leftrightarrow 1=e^{-(1)+\lambda}\sum_{j}e^{-\beta\epsilon_j} \\
         & Z\equiv e^{1+\lambda}= \sum_{j}e^{-\beta\epsilon_j} \rightarrow p_j=\frac{e^{-\beta\epsilon_j}}{Z}
    \end{aligned}
\end{equation}

Se l'energia fosse la stessa per ogni microstato, si otterrebbe che la probabilità di ogni microstato sarebbe analoga a quella del sistema microcanonico, ossia data dall'inverso della funzione di partizione.

\subsection{Significato fisico di $\beta$}
Si ricava di seguito il significato fisico del moltiplicatore di Lagrange $\beta$:

\begin{equation}
    \begin{aligned}
         & S=-k_b\sum_{j}p_j\ln{p_j}=-k_b\sum_{j}\frac{e^{-\beta \epsilon_j}}{Z}(\ln{e^{-\beta \epsilon_j}}-\ln{Z})=     \\
         & =k_b\beta\sum_{j}\frac{\epsilon_j e^{-\beta \epsilon_j}}{Z}+k_b\ln{Z}\sum_{j}\frac{e^{-\beta \epsilon_j}}{Z}= \\
         & =k_B\beta U+k_b\ln{Z}
    \end{aligned}
\end{equation}

Sotto l'ipotesi di minime variazioni di energia, le variazioni delle probabilità saranno minime:

*da terminare. Intero calcolo su "Calcoli integrativi*

Si ottiene:

\begin{equation}
    \beta=\frac{1}{k_BT}
\end{equation}

da cui risulta l'espressione dell'Energia libera di Helmholtz statistica:

\begin{equation}
    F=U-TS=-k_BT\ln{Z}
\end{equation}

Si è ricavato che massimizzare l'entropia equivale a minimizzare l'energia libera di Helmotz.

Come fatto per F, ogni quantità termodinamica è ottenibie a partire dalla funzione di partizione Z.

L'espressione di F risulta pertanto un'equazione "ponte".

\subsection{Oscillatore armonico quantistico}

La ricavazione della quantizzazione dell'energia dell'oscillatore armonico quantistico è esposta negli appunti di Meccanica Quantistica.

\begin{equation}
    \left\{
    \begin{aligned}
         & H=\frac{1}{2m}(\hat{p}^2+m^2\omega^2\hat{q}^2) \\
         & H\psi=\epsilon\psi
    \end{aligned}
    \right.
\end{equation}

si ottiene:

\begin{equation}
    \epsilon_j=\hbar\omega(j+\frac{1}{2})
\end{equation}

Segue l'espressione della funzione di partizione Z:

\begin{equation}
    Z=\sum_{j}e^{-\beta\epsilon_j}=\sum_{j}e^{-\beta\hbar\omega(j+\frac{1}{2})}=\frac{e^{-\frac{\beta\hbar\omega}{2}}}{1-e^{-\beta\hbar\omega}}
\end{equation}

da cui si ricava l'energia:

\begin{equation}
    \begin{aligned}
         & U=-\frac{1}{Z}\frac{\partial Z}{\partial \beta}= -\frac{\partial}{\partial \beta}\ln{Z}= \\
         & \frac{\hbar \omega}{2}\coth{\frac{\hbar \omega}{2k_BT}}
    \end{aligned}
\end{equation}

\section{Gas ideale}
Si definisce gas ideale un sistema di particelle non interagenti.

\subsection{Distinguibilità e indistinguibilità}
Particelle identiche quantistiche sono indistinguibili, pertanto non indicizzabili.

Classicamente ciò non accade, motivo per cui la funzione Z classica risulta fattorizzabile:

\begin{equation}
    Z= \sum \frac{N!}{\prod_in_i!}e^{-\beta\sum n_i\epsilon_i}=\left(\sum e^-{\beta \epsilon_j}\right)^N=Z_i^N
\end{equation}

dove la produttoria compare per via della somma su tutte le possibili configurazioni di particelle. L'ultima uguaglianza è dovuta all'identità del coefficiente multinomiale.

Il caso delle particelle indistinguibili è più complesso, in quanto la Z non è fattorizzabile, pertanto ci limiteremo per il momento a casistiche particolari.

L'ipotesi aggiuntiva richiesta è quella di occupazione singola, che comporta la possibilità di trascurare le configurazioni in cui due o più particelle occupino lo stesso livello energetico.
Ciò si realizzerà in sistemi a bassa densità, tali per cui la distanza tra le particelle è molto maggiore della lunghezza d'onda di De Broglie.
In questo limite, pertanto, la funzione di partizione del sistema di particelle indistinguibili si riduce a quella di particelle distinguibili.

Nel caso di occupazione singola, per particelle indistinguibili:

\begin{equation}
    Z=\sum_{n_s} e^{-\beta E_{{n_s}}}
\end{equation}

La funzione di partizione è pertanto desumibile dall'analisi energetica di una particella singola in una buca di potenziale \footnote{
    Un procedimento analogo è stato seguito in "Fisica Nucleare e Subnucleare" per il modello di nucleo atomico di gas di fermioni.
}

L'Hamiltoniana di una particella in una buca di potenziale è data da:

\begin{equation}
    H=\frac{p^2}{2m}+V(x)
\end{equation}

Dunque l'equazione di Schrödinger stazionaria è:

\begin{equation}
    \left\{
    \begin{aligned}
         & -\frac{\hbar^2}{2m}\frac{d^2\psi}{dx^2}+V(x)\psi=E\psi \\
         & \psi(0)=\psi(a)=0
    \end{aligned}
    \right.
\end{equation}

La soluzione è data, in 3D, da:

\begin{equation}
    \psi_n(x)=\sqrt{\frac{2}{L}}\sin{\frac{n\pi x}{L}}
\end{equation}

con relativa quantizzazione dell'energia:

\begin{equation}
    E_n=\frac{\hbar^2\pi^2(n_x^2+n_y^2+n_z^2)}{2mL^2}
\end{equation}

E' ora possibile calcolare la funzione di partizione Z per particelle distinguibili:

\begin{equation}
    \begin{aligned}
         & Z=\sum e^{-\frac{-\pi^2\hbar^2}{2mL^2}(n_x^2+n_y^2+n_z^2)\beta}= \\
         & \sum e^{-\frac{\pi^2\hbar^2}{2mL^2k_bT}(n_x^2+n_y^2+n_z^2)}=     \\
         & =\sum e^{-\frac{\theta_t}{T}(n_x^2+n_y^2+n_z^2)}=                \\
         & \left(\sum e^{-\frac{\theta_tn_x^3}{T}}\right)^3
    \end{aligned}
\end{equation}

dove $\theta_t$ è la temperatura caratteristica del moto di traslazione.

Per $T>>\theta_t$:

\begin{equation}
    \begin{aligned}
         & Z \rightarrow \left(\int_{0}^{\infty} e^{-\frac{\theta_tn^2}{T}}dn\right)^3=                                                               \\
         & =\left(\frac{1}{2}\sqrt{\frac{\pi T}{\theta_t}}\right)^3= \left(\frac{mk_bT}{2\pi\hbar^2}\right)^{\frac{3}{2}}V= n_QV= \frac{V}{\lambda^3}
    \end{aligned}
\end{equation}

dove $n_Q$ è la densità di stati quantistica, e $\lambda$ è la lunghezza d'onda di De Broglie.

\subsection{Proprietà del gas perfetto monoatomico}

Per particelle indistinguibili:

\begin{equation}
    Z=\frac{Z_D^N}{N!}=\frac{(n_QV)^N}{N!}\simeq \frac{1}{\sqrt{2\pi N}}\left(\frac{en_Q}{n}\right)^N
\end{equation}

Ora che si è trovata la funzione di partizione Z per un gas ideale composto da particelle indistinguibili, è possibile calcolare
le quantità termodinamiche del sistema.

\subsection{Entropia di mescolamento}

L'equazione di Sackur-Tetrode è:

\begin{equation}
    S=\frac{\partial F}{\partial T}=Nk_b\left[\ln{\frac{n_Q}{n}}+\frac{5}{2}\right]
\end{equation}


Nel caso di due sistemi separati, composti dallo stesso tipodi particella, si ha:

\begin{equation}
    \begin{aligned}
         & S^i=2Nk_b\left[\ln{\frac{n_QV}{N}}+\frac{5}{2}\right]   \\
         & S_f=2Nk_b\left[\ln{\frac{n_Q2V}{2N}}+\frac{5}{2}\right] \\
         & \Delta S=0
    \end{aligned}
\end{equation}

come ci si aspettava, per via dell'indistinguibilità delle particelle.

Nel caso opposto di due sistemi contenenti 2 tipi di particelle, si ha:

\begin{equation}
    \begin{aligned}
         & S_i=Nk_b\left[\ln{\frac{n_Q^AV}{N}}+\frac{5}{2}\right]+Nk_b\left[\ln{\frac{n_Q^BV}{N}}+\frac{5}{2}\right]    \\
         & S_f= Nk_b\left[\ln{\frac{2n_Q^AV}{N}}+\frac{5}{2}\right]+Nk_b\left[\ln{\frac{2n_Q^BV}{N}}+\frac{5}{2}\right] \\
         & \Delta S=2Nk_b\ln{2}
    \end{aligned}
\end{equation}


\subsection{Teorema di equipartizione dell'energia}

Se l'energia di un sistema classico è la somma di n modi quadratici e il sistema è in contatto con un bagno termico a temperatura T,
l'energia media del sistema è data da:

\begin{equation}
    U=\frac{n}{2}k_BT
\end{equation}

ossia, l'energia è equamente suddivisa sui gradi di libertà.
Di seguito si dimostra.

L'energia di un sistema ad N gradi di libertà quadratici è data da:
\begin{equation}
    \begin{aligned}
         & E({x_i})=\sum_{i}^{N}\epsilon_i(x_i)=\sum_{i}^{N}c_ix_i^2 \\
         & U=<E>=<\sum_{i}^{N}\epsilon_i>=\sum_{i}^{N}<\epsilon_i>
    \end{aligned}
\end{equation}

$<\epsilon_j>$ è la media statistica, estratta per mezzo della distribuzione canonica:

\begin{equation}
    \begin{aligned}
         & <\epsilon_j>=\int \prod_{i}^{N}dx_i\epsilon_jP(\epsilon_j)= \frac{\int d\eta \epsilon_je^{-\beta \sum \epsilon_i}}{\int d\eta e^{-\beta \sum \epsilon_i}} \\
         & = \frac{\int dx_j\epsilon_je^{-\beta \epsilon_j}}{\int dx_je^{-\beta \epsilon_j}}=\frac{1}{2}k_bT
    \end{aligned}
\end{equation}


\section{Insieme Gran Canonico}
Un insieme termodinamico è gran canonico se i sistemi che lo compongono sono aperti, a contatto con
un bagno termico e di particelle.
I costrains sono pertanto la temperatura, il volume e il potenziale chimico.

\subsection{Potenziale chimico}

The concept of chemical potential naturally emerges from the minimization of the free energy
of the system composed by the ensamble and the bath, which is therefore canonical.

One, indeed, finds:

\begin{equation}
    \frac{\partial}{\partial N_R}F_R|_{T,V}=\frac{\partial}{\partial N}F_S|_{T,V}\equiv \mu
\end{equation}

Moreover, examining the differential of the entropy, one finds:

\begin{equation}
    dS=\frac{dU}{T}+\frac{PdV}{T}-\frac{\mu dN}{T}
\end{equation}


\subsection{Gran Canonical Partition Function}

The process of derivation of the partition function for the grand canonical ensamble is analogous to the canonical one,
meaning it goes through the maximization of the entropy of the system.

One finds:

\begin{equation}
    \begin{aligned}
        \Xi= \sum_{N=0}^{+\infty}Z(N)e^{\beta\mu N} \\
    \end{aligned}
\end{equation}

\subsection{Grand Potential}

Thanks to the expression of the grand canonical partition function, the
entropy might be written as:

\begin{equation}
    S= k_bT\ln{\Xi}+\frac{U-\mu N}{T}
\end{equation}

which can be rearranged defining the Grand Potential $\Phi$:

\begin{equation}
    \Phi=k_bT\ln{\Xi}=\mu N-F
\end{equation}

from which any thermodinamical quantity is obtainable, as shown in the compendium.

For example, the average number of particle is:

\begin{equation}
    \mathcal{N}=<N>=\frac{\sum_{N=0}^{+\infty} N Z(N)e^{\mu N}}{\Xi}= \frac{\partial}{\partial \mu}\Psi
\end{equation}


\section{Quantum Statistical Mechanics}

\subsection{Maxwell Boltzmann Statistics}

The Maxwell-Boltzmann statistics describes an ensable of non interacting quantum particles in the classical
approximation of dilute gas, meaning the grand canonical partition function is:

\begin{equation}
    \Xi=\sum_{N=0}^{+\infty}\frac{Z^N}{N!}e^{\beta\mu N}
\end{equation}

Therefore, the average number of particles per energy level is obtainable from the great potential as:

\begin{equation}
    \mathcal{N}=\frac{1}{\beta}\frac{\partial}{\partial \mu}\ln{\Xi}=\sum_{s} e^{-\beta(\epsilon_s-\mu)}
\end{equation}

so that:

\begin{equation}
    <n_s>=e^\beta(\mu-\epsilon_s)
\end{equation}


\subsection{Fermi-Dirac Statistics}

The Fermi-Dirac statistics is necessary whenever the fermionic nature of the particles
can't be disregarded.
It can be derived from the grand canonical partition function, and it is given by:

\begin{equation}
    <n_s>=\frac{1}{e^{\beta(\epsilon_s-\mu)}+1}
\end{equation}

Some physical observations are suitable:

\begin{itemize}
    \item The average number of particles per energy level is always less than 1.
    \item If $\mu>\epsilon_s$, as T goes to 0, the average number of particles per energy level goes to 1,
          whereas if $\mu<\epsilon_s$, it goes to 0. This implies that the average number of particles per energy level tends to
          the Heaviside step function.
    \item The T=0 potential is called Fermi Energy, and it is the energy of the highest occupied state.
\end{itemize}

\subsection{Bose-Einstein Statistics}

The Bose-Einstein statistics is necessary whenever the bosonic nature of the particles
can't be disregarded.
It can be derived from the grand canonical partition function, and it is given by:

\begin{equation}
    <n_s>=\frac{1}{e^{\beta(\epsilon_s-\mu)}-1}
\end{equation}

Some physical observations are suitable:

\begin{itemize}
    \item The average number of particles per energy level is always greater than 1.
    \item If $\mu<\epsilon_s$, as T goes to 0, the average number of particles per energy level goes to 0,
          whereas if $\mu>\epsilon_s$, it goes to -1, which is non-physical. This behaviour is indeed prevented by
          the fact that the chemical potential is never greater than the energy of the state, at any temperature.
\end{itemize}

\newpage
\section{Compendium}


\fbox{
    \begin{minipage}{0.9\textwidth}
        \textbf{Grand Canonical Ensemble}
        \begin{itemize}
            \item Constrains: T,V,$\mu$.
            \item \( \mu = \frac{\partial F}{\partial N} \).
            \item \( \Xi = \sum_{N=0}^{+\infty} Z(N) e^{\beta \mu N} \).
            \item \( \Phi = k_B T \ln \Xi = \mu N - F \).
            \item <N>=\(\frac{1}{\beta}\frac{\partial}{\partial \mu}\ln{\Xi}\)
        \end{itemize}

        \textbf{Quantum Statistical Mechanics}
        \begin{itemize}
            \item Maxwell-Boltzmann Statistics: \(<n_s>=e^\beta(\mu-\epsilon_s)\).
            \item Fermi-Dirac Statistics: \(<n_s>=\frac{1}{e^{\beta(\epsilon_s-\mu)}+1}\).
            \item Bose-Einstein Statistics: \(<n_s>=\frac{1}{e^{\beta(\epsilon_s-\mu)}-1}\).
            \item \( g(E)= \frac{dN}{dE}=\frac{g_sV}{4\pi}(\frac{2m}{\hbar^2})^{\frac{3}{2}}\sqrt{E} \)
        \end{itemize}

    \end{minipage}
}

\newpage
\section{Compendium of Hyperbolic and Trigonometric Functions}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Function} & \textbf{Exponential Expression}     & \textbf{Derivative} & \textbf{McLaurin Expansion}                    \\
        \hline
        $\sinh{x}$        & $\frac{e^x - e^{-x}}{2}$            & $\cosh{x}$          & $x + \frac{x^3}{3!} + \frac{x^5}{5!} + \cdots$ \\
        \hline
        $\cosh{x}$        & $\frac{e^x + e^{-x}}{2}$            & $\sinh{x}$          & $1 + \frac{x^2}{2!} + \frac{x^4}{4!} + \cdots$ \\
        \hline
        $\tanh{x}$        & $\frac{e^x - e^{-x}}{e^x + e^{-x}}$ & $1 - \tanh^2{x}$    & $x - \frac{x^3}{3} + \frac{2x^5}{15} + \cdots$ \\
        \hline
        $\coth{x}$        & $\frac{e^x + e^{-x}}{e^x - e^{-x}}$ & $1 - \coth^2{x}$    & $x + \frac{x^3}{3} + \frac{x^5}{5} + \cdots$   \\
        \hline
        $\sin{x}$         & $\frac{e^{ix} - e^{-ix}}{2i}$       & $\cos{x}$           & $x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots$ \\
        \hline
        $\cos{x}$         & $\frac{e^{ix} + e^{-ix}}{2}$        & $-\sin{x}$          & $1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots$ \\
        \hline
        $\tan{x}$         & $\frac{\sin{x}}{\cos{x}}$           & $1 + \tan^2{x}$     & $x + \frac{x^3}{3} + \frac{2x^5}{15} + \cdots$ \\
        \hline
        $\cot{x}$         & $\frac{\cos{x}}{\sin{x}}$           & $-1 - \cot^2{x}$    & $x - \frac{x^3}{3} + \frac{x^5}{5} + \cdots$   \\
        \hline
    \end{tabular}
\end{center}

\section{Compendium of Series Convergence}


\renewcommand{\arraystretch}{1.5}
\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Series}                                       & \textbf{Convergence Condition} & \textbf{Sum}                       \\
        \hline
        $\sum_{n=0}^{\infty} x^n$                             & $|x| < 1$                      & $\frac{1}{1-x}$                    \\
        \hline
        $\sum_{n=1}^{\infty} \frac{1}{n^p}$                   & $p > 1$                        & $\zeta(p)$ (Riemann zeta function) \\
        \hline
        $\sum_{n=0}^{\infty} \frac{x^n}{n!}$                  & $\forall x \in \mathcal{R}$    & $e^x$                              \\
        \hline
        $\sum_{n=0}^{\infty} (-1)^n x^n$                      & $|x| < 1$                      & $\frac{1}{1+x}$                    \\
        \hline
        $\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}$            & $\forall x \in \mathcal{R}$    & $\ln(2)$                           \\
        \hline
        $\sum_{n=1}^{\infty} \frac{x^n}{n}$                   & $|x| \leq 1, x \neq 1$         & $-\ln(1-x)$                        \\
        \hline
        $\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}$ & $\forall x \in \mathcal{R}$    & $\sin(x)$                          \\
        \hline
        $\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}$     & $\forall x \in \mathcal{R}$    & $\cos(x)$                          \\
        \hline
        $\sum_{n=1}^{\infty} \frac{1}{n(n+1)}$                & $\forall n \in \mathcal{N}$    & $1$                                \\
        \hline
    \end{tabular}
\end{center}


\end{document}
