\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[most]{tcolorbox}

\title{Fisica della Materia}
\author{Sabattini Manginella Cesare}
\date{Winter 2024}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}
ATTENZIONE: formulario ancora in fase di sviluppo. Alcune informazioni potrebbero essere incomplete o errate.
E' inoltre in corso la riscrittura in inglese.

\section{Micro and Macrostates}
A macrostate is the state of a system, emerging from different microscopical configurations, namely microstates.
The number of microstates corrisponding to a macrostate is called multiplicity $\Omega$.

\subsection{Entropy}
Statistically, the entropy aims to measure the degree of "ignorance" about the microscopical state of a thermodynamical system.
The formula of the S($\Omega$) function can be deduced stating the following properties:

\begin{itemize}
    \item S(1)=0.
    \item $\Omega_1>\Omega_2$ $\rightarrow$ S($\Omega_1$)>S($\Omega_2$).
    \item $\Omega=\Omega_1\Omega_2$ $\rightarrow$ S($\Omega$)=S($\Omega_1$)+S($\Omega_2$).
\end{itemize}

Hence, ultimately, one can find the expression of the entropy for a macrostate from:

\begin{tcolorbox}[colframe=gray!50, colback=gray!10, coltitle=black, title=Boltzmann Entropy]
    Given a set of equiprobable configurations, the Boltzmann entropy can be defined from the partition function:
    \begin{equation}
        S = k \log \Omega
    \end{equation}
\end{tcolorbox}

\section{The Microcanonical Ensamble}
A set of isoleted systems is called Microcanonical Ensamble. Since it does not exchange energy and particles,
the constrains are U, V, N.

\subsection{Temperature T}
Thermally coupling two systems, isolated from the rest of the universe, the multiplicity of the combined system is given by the product of the multiplicities of the two systems:

\begin{equation}
    \left\{
    \begin{aligned}
         & U=U_1+U_2                                               \\
         & N=N_1+N_2                                               \\
         & \Omega(N,U_1,U_2) = \Omega_1(N_1,U_1) \Omega_2(N_2,U_2)
    \end{aligned}
    \right.
\end{equation}

The most probable state is the one that maximizes the entropy, therefore the multiplicity.
For the central limit theorem, as $N_1, N_2 \rightarrow \infty$, the fluctuations are negligible, since the standard deviation is proportional to the inverse of the square root of the number of particles.

Maximizing $\Omega(N, U, U_1)$, one can define the doncept of temperature T:

\begin{equation}
    \begin{aligned}
         & \frac{\partial}{\partial U_1}[\Omega(N, U)]_{U=\hat{U}} = \frac{\partial}{\partial U}[\Omega_1(N_1, U_1)\Omega_2(N_2, U_2)]_{U=\hat{U}} =                                     \\
         & \frac{\partial}{\partial U_1}\Omega_1|_{U_1=\hat{U_1}}\Omega_2|_{U_2=\hat{U_2}} + \Omega_1|_{U_1=\hat{U_1}}\frac{\partial}{\partial U_2}\Omega_2|_{U_2=\hat{U_2}} \rightarrow \\
         & \frac{\partial}{\partial U_1}\ln{\Omega_1}|_{U_1=\hat{U_1}}=\frac{\partial}{\partial U_2}\ln{\Omega_2}|_{U_2=\hat{U_2}}
    \end{aligned}
\end{equation}

These functions depend on two independent variables, so they must equalize to a constant, which ultimately defines the temperature T:

\begin{equation}
    \begin{aligned}
         & \beta=\frac{\partial}{\partial U}\ln{\Omega(N,U)}|_{U=\hat{U}} \equiv \frac{1}{k_BT}= \frac{1}{k_B}\frac{\partial S}{\partial U}|_{N,V} \\
    \end{aligned}
\end{equation}

\subsection{Entropia di Gibbs}
The Gibbs Entropy generalizes the Boltzmann Entropy to the case of non-isolated systems, where different microstates have different probabilities.

\begin{equation}
    S_G=-k_B\sum_{i}p_i\ln{p_i}
\end{equation}

Maximizing the Gibbs Entropy with the constraint of unitary of the sum of the probabilities, one finds that
the Boltzmann Entropy is actually a particular case of the Gibbs Entropy for equiprobable microstates.


\section{The Canonical Ensamble}

An ensamble of closed systems in thermal contact with a bath is called canonical.
This implies that the constrains of this ensamble are N, T and V, meaning that the
energy can instead fluctuate around a mean value U.

\subsection{Partition Function}

Maximizing the Gibbs entropy similiarly as done for the microcanonical ensamble, but with the constraint of fixed energy, one finds the partition function:

\begin{equation}
    \begin{aligned}
         & S= -k_B\sum_{j}p_j\ln{p_j}-\lambda\left(\sum_{j}p_j-1\right)-\beta\left(\sum_{j}\epsilon_jp_j-U\right) \\
         & \frac{dS}{dp_j}=0 \rightarrow p_j=e^{-\beta\epsilon_j-\lambda-1} \rightarrow                           \\
         & \rightarrow 1=e^{-(1+\lambda)}\sum_{j}e^{-\beta\epsilon_j}                                             \\
         & Z\equiv e^{1+\lambda}=\sum_{j}e^{-\beta\epsilon_j} \rightarrow p_j=\frac{e^{-\beta\epsilon_j}}{Z}
    \end{aligned}
\end{equation}

As expected, the probability of a microstate is no longer uniform, but depends on its energy.
As a matter of fact, one can find the microcanonical probability if all the microstates have the same energy.

\subsubsection{$\beta$ Lagrange multiplier}

The physical content of the $\beta$ multiplier can be derived from computing
an infinitesimal variation of the entropy:

\begin{equation}
    \left\{
    \begin{aligned}
         & \sigma S= S(p_j+\delta p_j)-S(p_j) = -k_B\sum_{j}(\ln{(p_j+\delta p_j)}-\ln{p_j})=...=                                                        \\
         & = -k_B\beta\sigma U \rightarrow \beta=\frac{1}{k_B}\frac{\sigma S}{\sigma U}\simeq \frac{1}{k_B}\frac{\partial S}{\partial U}= \frac{1}{k_BT}
    \end{aligned}
    \right.
\end{equation}

\subsection{Free Energy}
Computing the physical expression of $\beta$, one can rewrite the entropy and find the free energy in terms of partition function Z:

\begin{equation}
    \begin{aligned}
         & S=-k_b\sum_{j}p_j\ln{p_j}=-k_b\sum_{j}\frac{e^{-\beta \epsilon_j}}{Z}(\ln{e^{-\beta \epsilon_j}}-\ln{Z})=     \\
         & =k_b\beta\sum_{j}\frac{\epsilon_j e^{-\beta \epsilon_j}}{Z}+k_b\ln{Z}\sum_{j}\frac{e^{-\beta \epsilon_j}}{Z}= \\
         & =k_B\beta U+k_b\ln{Z}=\frac{U}{T}-k_BT\ln{Z} \rightarrow U-TS=-k_BT\ln{Z}=F
    \end{aligned}
\end{equation}

Maximizing the entropy is hence equivalent to minimizing the free energy of Helmotz.

As done for F, every thermodynamical quantity is obtainable from the partition function Z.
Most of them are presented in the compendium of this section.


\section{Ideal Gas}

An ideal gas in contact with a fixed temperature external bath is well described by the canonical ensamble,
since the constrains are satisfied.

\subsection{Particle distinguishability}

The distinguishability is the property that in statistical mechanics mainly discerns classical particles from quantistic ones,
beside the bosonic and fermionic nature, whether quantum.
This concept has important repercussions on the partition function of the system.


\subsubsection{Distinguishable particles}

Given a set of N classical distinguishable particles, the partition function is:

\begin{equation}
    Z= \sum \frac{N!}{\prod_in_i!}e^{-\beta\sum n_i\epsilon_i}=Z_1^N
\end{equation}

where the sum is over all the possible configurations of particles. In the last equality, the multinomial coefficient is used.

\subsubsection{Indistinguishable particles}

The case of indistinguishable particles is hereby treated in the approximation of single occupation, which is valid for low density systems, where the distance between particles is much greater than the De Broglie wavelength,
which directly implies that the product of the occupation numbers for each configuration is one.
Moreover, since the particles are non indexable, the partition function is reduced to that of distinguishable particles, divided by N!:

\begin{equation}
    Z=\frac{Z_1^N}{N!}=\sum_{{n_s}}e^-\beta\sum_{s}E_{\{n_s\}}
\end{equation}

\subsection{Quantum ideal gas in a box}

In the low density approximation, it's easy to find the partition function of an ensamble of particles,
knowing the single particle one.
In the model of a gas constrained in an infinite potential well, the single particle partition function is given by
\footnote{
    The complete derivation of the energy for a quantum particle constrained in a box can be found in the Quantum Mechanics notes.
}:

\begin{equation}
    \begin{aligned}
         & Z=\sum e^{-\frac{-\pi^2\hbar^2}{2mL^2}(n_x^2+n_y^2+n_z^2)\beta}=  \\
         & \sum e^{-\frac{\pi^2\hbar^2}{2mL^2k_bT}(n_x^2+n_y^2+n_z^2)}\equiv \\
         & \equiv\sum e^{-\frac{\theta_t}{T}(n_x^2+n_y^2+n_z^2)}=            \\
         & =\left(\sum e^{-\frac{\theta_tn_x^3}{T}}\right)^3
    \end{aligned}
\end{equation}

Per $T>>\theta_t$, the sum is approximated by an integral:

\begin{equation}
    \begin{aligned}
         & Z \rightarrow \left(\int_{0}^{\infty} e^{-\frac{\theta_tn^2}{T}}dn\right)^3=                                                                    \\
         & =\left(\frac{1}{2}\sqrt{\frac{\pi T}{\theta_t}}\right)^3= \left(\frac{mk_bT}{2\pi\hbar^2}\right)^{\frac{3}{2}}V= n_QV= \frac{V}{\lambda_{dB}^3}
    \end{aligned}
\end{equation}

where $\lambda_{dB}$ is the De Broglie wavelength of the particle, so $n_Q$ is the number of quantum states density in the semiclassical limit.

When N particles are considered, the partition function is:

\begin{equation}
    Z=\frac{Z_1^N}{N!}=\frac{(n_QV)^N}{N!}\simeq \frac{1}{\sqrt{2\pi N}}\left(\frac{g_sen_Q}{n}\right)^N
\end{equation}

where $g_s$ is the spin degeneracy of the particle.


\subsection{Properties of the monoatomic ideal gas}

Any property of the ideal gas can be derived from the partition function,
simply using their definition and the canonical bridge equation, given by the Helmholtz free energy.

\subsubsection{Entropy of mixing}

A curious property of the ideal gas is the entropy of mixing, derivable from the partition function Z and
leading to the Sackur-Tetrode equation:

\begin{equation}
    S=-Nk_b\left[\ln{\frac{n_QV}{N}}+\frac{5}{2}\right]
\end{equation}

Here we can distinguish two cases:

\begin{itemize}
    \item Two separated systems, composed by the same type of particle, have a null entropy variation when mixed.

          \begin{equation}
              \begin{aligned}
                   & S_i=2Nk_b\left[\ln{\frac{n_QV}{N}}+\frac{5}{2}\right]   \\
                   & S_f=2Nk_b\left[\ln{\frac{n_Q2V}{2N}}+\frac{5}{2}\right] \\
                   & \Delta S=0
              \end{aligned}
          \end{equation}

    \item Two separated systems, composed by two types of particles, have a positive entropy variation when mixed.

          \begin{equation}
              \begin{aligned}
                   & S_i=Nk_b\left[\ln{\frac{n_Q^AV}{N}}+\frac{5}{2}\right]+Nk_b\left[\ln{\frac{n_Q^BV}{N}}+\frac{5}{2}\right]    \\
                   & S_f= Nk_b\left[\ln{\frac{2n_Q^AV}{N}}+\frac{5}{2}\right]+Nk_b\left[\ln{\frac{2n_Q^BV}{N}}+\frac{5}{2}\right] \\
                   & \Delta S=2Nk_b\ln{2}
              \end{aligned}
          \end{equation}
\end{itemize}

This is no surprise, since the particles are indistinguishable, so the reversibility of the process is different in the two instances.


\subsection{Energy equipartition theorem}

\begin{tcolorbox}[colframe=black, colback=gray!10, coltitle=white, title=Energy equipartition theorem]


    \begin{equation}
        U=\frac{n}{2}k_BT
    \end{equation}
    where \( n \) is the number of quadratic degrees of freedom of the system.
\end{tcolorbox}


L'energia di un sistema ad N gradi di libertà quadratici è data da:
\begin{equation}
    \begin{aligned}
         & E({x_i})=\sum_{i}^{N}\epsilon_i(x_i)=\sum_{i}^{N}c_ix_i^2                                                                                                 \\
         & U=<E>=<\sum_{i}^{N}\epsilon_i>=\sum_{i}^{N}<\epsilon_i>                                                                                                   \\
         & <\epsilon_j>=\int \prod_{i}^{N}dx_i\epsilon_jP(\epsilon_j)= \frac{\int d\eta \epsilon_je^{-\beta \sum \epsilon_i}}{\int d\eta e^{-\beta \sum \epsilon_i}} \\
         & = \frac{\int dx_j\epsilon_je^{-\beta \epsilon_j}}{\int dx_je^{-\beta \epsilon_j}}=\frac{1}{2}k_bT
    \end{aligned}
\end{equation}


\section{The Gran Canonical Ensamble}

An ensamble of open system in contact with an external bath is called grand canonical,
so the energy and the number of particles can fluctuate around mean values.
Therefore, the constrains are T, V, $\mu$, which is the chemical potential.

\subsection{Chemical Potential}

The concept of chemical potential naturally emerges from the minimization of the free energy
of the system composed by the ensamble and the bath, which is therefore canonical.

One, indeed, finds:

\begin{equation}
    \frac{\partial}{\partial N_R}F_R|_{T,V}=\frac{\partial}{\partial N}F_S|_{T,V}\equiv \mu
\end{equation}

Moreover, examining the differential of the entropy, one finds:

\begin{equation}
    dS=\frac{dU}{T}+\frac{PdV}{T}-\frac{\mu dN}{T}
\end{equation}


\subsection{Gran Canonical Partition Function}

The process of derivation of the partition function for the grand canonical ensamble is analogous to the canonical one,
meaning it goes through the maximization of the entropy of the system.

One finds:

\begin{equation}
    \begin{aligned}
        \Xi= \sum_{N=0}^{+\infty}Z(N)e^{\beta\mu N} \\
    \end{aligned}
\end{equation}

\subsection{Grand Potential}

Thanks to the expression of the grand canonical partition function, the
entropy might be written as:

\begin{equation}
    S= k_bT\ln{\Xi}+\frac{U-\mu N}{T}
\end{equation}

which can be rearranged defining the Grand Potential $\Phi$:

\begin{equation}
    \Phi=k_bT\ln{\Xi}=\mu N-F
\end{equation}

from which any thermodinamical quantity is obtainable, as shown in the compendium.

For example, the average number of particle is:

\begin{equation}
    \mathcal{N}=<N>=\frac{\sum_{N=0}^{+\infty} N Z(N)e^{\mu N}}{\Xi}= \frac{\partial}{\partial \mu}\Psi
\end{equation}


\newpage

\begin{tcolorbox}[colframe=black, colback=white, coltitle=white, sharp corners, title=\textbf{Compendium}, fonttitle=\large\bfseries, coltitle=blue!20]
    \textbf{Topic 1}
    \vspace{0.5em}

\end{tcolorbox}

\section{Quantum Statistical Mechanics}

\subsection{Maxwell Boltzmann Statistics}

The Maxwell-Boltzmann statistics describes an ensable of non interacting quantum particles in the classical
approximation of dilute gas, meaning the grand canonical partition function is:

\begin{equation}
    \Xi=\sum_{N=0}^{+\infty}\frac{Z^N}{N!}e^{\beta\mu N}
\end{equation}

Therefore, the average number of particles per energy level is obtainable from the great potential as:

\begin{equation}
    \mathcal{N}=\frac{1}{\beta}\frac{\partial}{\partial \mu}\ln{\Xi}=\sum_{s} e^{-\beta(\epsilon_s-\mu)}
\end{equation}

so that:

\begin{equation}
    <n_s>=e^\beta(\mu-\epsilon_s)
\end{equation}


\subsection{Fermi-Dirac Statistics}

The Fermi-Dirac statistics is necessary whenever the fermionic nature of the particles
can't be disregarded.
It can be derived from the grand canonical partition function, and it is given by:

\begin{equation}
    <n_s>=\frac{1}{e^{\beta(\epsilon_s-\mu)}+1}
\end{equation}

Some physical observations are suitable:

\begin{itemize}
    \item The average number of particles per energy level is always less than 1.
    \item If $\mu>\epsilon_s$, as T goes to 0, the average number of particles per energy level goes to 1,
          whereas if $\mu<\epsilon_s$, it goes to 0. This implies that the average number of particles per energy level tends to
          the Heaviside step function.
    \item The T=0 potential is called Fermi Energy, and it is the energy of the highest occupied state.
\end{itemize}

\subsection{Bose-Einstein Statistics}

The Bose-Einstein statistics is necessary whenever the bosonic nature of the particles
can't be disregarded.
It can be derived from the grand canonical partition function, and it is given by:

\begin{equation}
    <n_s>=\frac{1}{e^{\beta(\epsilon_s-\mu)}-1}
\end{equation}

Some physical observations are suitable:

\begin{itemize}
    \item The average number of particles per energy level is always greater than 1.
    \item If $\mu<\epsilon_s$, as T goes to 0, the average number of particles per energy level goes to 0,
          whereas if $\mu>\epsilon_s$, it goes to -1, which is non-physical. This behaviour is indeed prevented by
          the fact that the chemical potential is never greater than the energy of the state, at any temperature.
\end{itemize}

\newpage
\section{Compendium of Hyperbolic and Trigonometric Functions}

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Function} & \textbf{Exponential Expression}     & \textbf{Derivative} & \textbf{McLaurin Expansion}                    \\
        \hline
        $\sinh{x}$        & $\frac{e^x - e^{-x}}{2}$            & $\cosh{x}$          & $x + \frac{x^3}{3!} + \frac{x^5}{5!} + \cdots$ \\
        \hline
        $\cosh{x}$        & $\frac{e^x + e^{-x}}{2}$            & $\sinh{x}$          & $1 + \frac{x^2}{2!} + \frac{x^4}{4!} + \cdots$ \\
        \hline
        $\tanh{x}$        & $\frac{e^x - e^{-x}}{e^x + e^{-x}}$ & $1 - \tanh^2{x}$    & $x - \frac{x^3}{3} + \frac{2x^5}{15} + \cdots$ \\
        \hline
        $\coth{x}$        & $\frac{e^x + e^{-x}}{e^x - e^{-x}}$ & $1 - \coth^2{x}$    & $x + \frac{x^3}{3} + \frac{x^5}{5} + \cdots$   \\
        \hline
        $\sin{x}$         & $\frac{e^{ix} - e^{-ix}}{2i}$       & $\cos{x}$           & $x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots$ \\
        \hline
        $\cos{x}$         & $\frac{e^{ix} + e^{-ix}}{2}$        & $-\sin{x}$          & $1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots$ \\
        \hline
        $\tan{x}$         & $\frac{\sin{x}}{\cos{x}}$           & $1 + \tan^2{x}$     & $x + \frac{x^3}{3} + \frac{2x^5}{15} + \cdots$ \\
        \hline
        $\cot{x}$         & $\frac{\cos{x}}{\sin{x}}$           & $-1 - \cot^2{x}$    & $x - \frac{x^3}{3} + \frac{x^5}{5} + \cdots$   \\
        \hline
    \end{tabular}
\end{center}

\section{Compendium of Series Convergence}


\renewcommand{\arraystretch}{1.5}
\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Series}                                       & \textbf{Convergence Condition} & \textbf{Sum}                       \\
        \hline
        $\sum_{n=0}^{\infty} x^n$                             & $|x| < 1$                      & $\frac{1}{1-x}$                    \\
        \hline
        $\sum_{n=1}^{\infty} \frac{1}{n^p}$                   & $p > 1$                        & $\zeta(p)$ (Riemann zeta function) \\
        \hline
        $\sum_{n=0}^{\infty} \frac{x^n}{n!}$                  & $\forall x \in \mathcal{R}$    & $e^x$                              \\
        \hline
        $\sum_{n=0}^{\infty} (-1)^n x^n$                      & $|x| < 1$                      & $\frac{1}{1+x}$                    \\
        \hline
        $\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}$            & $\forall x \in \mathcal{R}$    & $\ln(2)$                           \\
        \hline
        $\sum_{n=1}^{\infty} \frac{x^n}{n}$                   & $|x| \leq 1, x \neq 1$         & $-\ln(1-x)$                        \\
        \hline
        $\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}$ & $\forall x \in \mathcal{R}$    & $\sin(x)$                          \\
        \hline
        $\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}$     & $\forall x \in \mathcal{R}$    & $\cos(x)$                          \\
        \hline
        $\sum_{n=1}^{\infty} \frac{1}{n(n+1)}$                & $\forall n \in \mathcal{N}$    & $1$                                \\
        \hline
    \end{tabular}
\end{center}


\end{document}
